{"cells":[{"metadata":{},"cell_type":"raw","source":"Part 1. Exploratory data analysis\nPerform an exploratory data analysis on the given dataset and share your findings.\n\nPart 2. Metric calculation\nWhat is the average duration between the 1st trip and the 2nd trip of customers? Note: Consider only the customers who have done 2 or more trips.\n\nPart 3. Model building\nBuild a model to predict trip_fare using travel_distance and travel_time. Measure the accuracy of the model and use the model to predict trip_fare for a trip with travel_distance of 3.5 kms and travel_time of 15 minutes.\n\nPart 4. Top Hex clusters\nTop 5 pairs of hex (resolution=8) clusters where most of the trips happened? You can refer to the library listed below to get hexid for a given latitude and longitude.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##PART 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndf = pd.read_excel(\"/kaggle/input/commute.xlsx\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##WE see no missing values in the dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Latitutes and Longitudes are not exactly numbers, but instead they will be treated as co-ordinates, so we will not\n#evaluate them as numbers as such","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['trip_id'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['customer_id'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#19139 customers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('customer_id').agg({'trip_id':'count'}).sort_values(by='trip_id',ascending=False).head(50).plot.bar(figsize=(20,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Above we see top 50 customers based on the number of rides they have taken","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##We see that Customer 279 has actually taken a lot more rides than all the other customers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##similarly we can find the customers which have taken the least number of rides:\n\ndf.groupby('customer_id').agg({'trip_id':'count'}).sort_values(by='trip_id',ascending=True).head(50).plot.bar(figsize=(20,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##so, we see that the least number of rides is actually only 1, which means that there are quite a few customers who just\n#took a single ride, so let's find out how many customers took only one ride until now","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfx = df.groupby('customer_id').agg({'trip_id':'count'}).reset_index()\n(dfx[dfx['trip_id']==1].shape[0]/dfx.shape[0])*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##so, 52.3% (approx) of customers took only one ride after installing the app, until now\n##This is a business insight to note and this will help us target these customers for offers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('customer_id').agg({'travel_distance':'mean'}).sort_values(by='travel_distance',ascending=False).head(100).plot.bar(figsize=(20,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Top 100 customers by the mean of their travel distance, showcased above","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('customer_id').agg({'travel_distance':'mean'}).sort_values(by='travel_distance',ascending=True).head(100).plot.bar(figsize=(20,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Bottom 100 customers by the mean of their travel distance, showcased above","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##So, we notice that one customer has traveled a mean distance of -1. Now, this could mean two things: Either the data was entered\n#incorrectly, or else the customer travelled in the wrong direction(opposite to the one shown in the map) for 1 KM\n##It could actually mean other things as well, but at this moment, we can understand that something did go wrong with this\n#customer\n##And the other customers who have not traveled at all, have traveled distance as 0. But, again, these customers do have\n#co-ordinates in the data, which means that they have surely booked rides, and then cancelled them\n#so, again an insight to note, that quite a few customers have cancelled rides, which is not a good sign.\n##These users again become a target, for promoting offers, so that they start travelling","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('customer_id').agg({'travel_time':'mean'}).sort_values(by='travel_time',ascending=False).head(100).plot.bar(figsize=(20,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[['travel_distance','travel_time','trip_fare']].corr()  ##Checking correlation among numeric variables","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.heatmap(df[['travel_distance','travel_time','trip_fare']].corr(),annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##We see that quite obviously, travel distance and trip fare are very much correlated to each other","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.heatmap(df[['pick_lat','pick_lng','drop_lat','drop_lng']].corr(),annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##We do see correlation among latitudes and longitudes, which is again very obvious because latitudes and longitudes are\n#used to measure the position of the vehicle/person","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfcopy = df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport datetime\nfrom datetime import timedelta\ndfcopy['timestamp'] = dfcopy['timestamp'].apply(lambda d: time.strftime('%m/%d/%Y %H:%M:%S',  time.gmtime(d/1000.)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfcopy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=dfcopy)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##So, if we see the last row, we can understand that the trip fare does not depend on the pick location, but trip fare\n#does depend on travel distance, but not travel time (which is a good thing for customers in busy citis with lots of traffic\n#since they won't have to pay more for spending time in the traffic)\n##Travel distance does not depend on pick and drop locations in any way, since we do see a properly spread cluster of values in\n#the scatterplot, and this is quite obvious in a real life perspective\n#Latitude VS Longitude scatterplot is not much interpretable at this moment(since it would be better to check it out\n#on a map, but of course the spread of values in the plot is what shows that trips are being taken all across the city/country\n#and not just in some specific location--of course, there might be ceratin areas where trips might be more, and we'll check\n#that out using clustering)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfcopy.dtypes[dfcopy.dtypes!=object].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in dfcopy.dtypes[dfcopy.dtypes!=object].index:\n    sns.boxplot(df[i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Latitudes and longitudes are definitely bound to have outliers, because there would be people taking trips from remote\n#areas of the city, almost everyday, but the number of those people would be very less, which is acceptable, and hence these\n#outliers are still important for our predictions then\n##Travel distance also sees a lot of outiers, particularly above the upper whisker, which could definitely signify that\n#certain people do prefer to take trips only when they have to travel to a very far off place, or let's say if they are late,\n#and they feel like they won't be able to make it in time to the far off place--this could be one of the many insights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfcopy['timestamp'].apply(lambda d: str(d)[6:10]).unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##So, we see we have data only for 2019 at the moment. If we had had data for other years as well, I would have created\n#a column for year too, for analyzing it through the years\n##For now, let's check the months:\ndfcopy['month'] = dfcopy['timestamp'].apply(lambda d: str(d)[3:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfcopy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['customer_id','month']).agg({'trip_id':'count'}).sort_values(by='trip_id',ascending=False).head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Above we can see that our top customers have travelled in which month, and how many trips they have taken in that month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('month').agg({'trip_id':'count'}).plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Above we can see the trend analysis of trips across months in the year 2019\n##Trips shot up from January to February (which gives us an insight to work upon offers, etc. in January)\n##and of course, if people are travelling extensively in February, we can try to cool down on the offers(since people are\n#already willing to travel much in this period--based on the trend)\n##Trips started falling in April and came to the lowest in June, but then again shot up in July\n##Again, it is very much possible that new offers were introduced in these months, which caused the trips to shoot up, or maybe\n##like based on the weather conditions in February, people started taking more rides\n##July is again a part of monsoon, so heavy rains could be a reason for trips shooting up. There could be many such reasons\n#which we can analyze based on which locations the data was collected from and what were the social, economic and weather\n#conditions in that area at the period of time which is being analyzed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Part 2. Metric calculation\nWhat is the average duration between the 1st trip and the 2nd trip of customers? Note: Consider only the customers who have done 2 or more trips.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfc  = df.groupby('customer_id').agg({'trip_id':'count'}).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfc[dfc['trip_id']>=2]['customer_id'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfimp = df.set_index('customer_id').loc[dfc[dfc['trip_id']>=2]['customer_id'].values].reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfimp.sort_values(by='travel_time',ascending=True)\n##To check whether the person travelled or not","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfimp.sort_values(by='trip_fare',ascending=True)\n##To check whether the person travelled or not","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##So, now we know that in dfimp, people have travelled at least twice, and none of these trips were cancelled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfimp['customer_id'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfimp.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfimp['customer_id'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport datetime\nfrom datetime import timedelta\ndfimp['timestamp'] = dfimp['timestamp'].apply(lambda d: time.strftime('%m/%d/%Y %H:%M:%S',  time.gmtime(d/1000.)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfimp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfimp[dfimp['customer_id']=='CUST_001'].head(2).iloc[0]['timestamp']\n##Trying for one customer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"difflist = []\nfor i in dfimp['customer_id'].unique():\n    datetimeFormat = '%m/%d/%Y %H:%M:%S'\n    dat1 = dfimp[dfimp['customer_id']==i].sort_values(by='timestamp',ascending=True).head(2).iloc[0]['timestamp']\n    dat2 = dfimp[dfimp['customer_id']==i].sort_values(by='timestamp',ascending=True).head(2).iloc[1]['timestamp']\n    diff = datetime.datetime.strptime(dat2, datetimeFormat) - datetime.datetime.strptime(dat1, datetimeFormat)\n    difflist.append(diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"difflist  #(based on whether the first value was greater or the second value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Above I have chosen the first two trips of all the people and calculated the time between those two trips\n##Now, we will calculate the average time spent by customers between their first two trips","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.array(difflist).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##WE can see that average duration between the 1st trip and the 2nd trip of customers is \n##days=1, seconds=2829, microseconds=693538","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Part 3. Model building\nBuild a model to predict trip_fare using travel_distance and travel_time. Measure the accuracy of the model and use the model to predict trip_fare for a trip with travel_distance of 3.5 kms and travel_time of 15 minutes."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df[['trip_fare','travel_distance','travel_time']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = data['trip_fare']\nX = data.drop(columns='trip_fare')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##We'll be building a linear regression model\n##Let us build a stats model first, to understand which variables are of importance here\n##The accuracy in case of Linear Regression is given by the Rsquare achieved (adjusted Rsquare is a measure obtained after\n#dropping the importance of the variables which are overfitting the model--but it does not neccessarily mean that the overfit\n#would have been removed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings \nwarnings.filterwarnings('ignore')\nimport statsmodels.api as sm\n\nmodel1 = sm.OLS(y,X).fit()\nmodel1.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = model1.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = pd.DataFrame(data=[3.5,15]).T.rename(columns={0:'travel_distance',1:'travel_time'})\nX_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nnp.sqrt(mean_squared_error(y,y_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Above we see the predicted trip_fare for a trip with travel_distance of 3.5 kms and travel_time of 15 minutes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##So, we see that the Rsquare and the adjusted Rsquare is the same, which basically means that none of the variables were\n#causing any overfit, and that the variables were not correlated(which we also saw using a Heatmap in the beginning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Now, let's build a machine learning model so we can predict out value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\n\nlr.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = pd.DataFrame(data=[3.5,15]).T.rename(columns={0:'travel_distance',1:'travel_time'})\nX_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = lr.fit(X,y)\ny_test_pred = lr.predict(X_test)\ny_train_pred = lr.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##The trip_fare for a trip with travel_distance of 3.5 kms and travel_time of 15 minutes is shown below:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Accuracy of the Machine Learning (regression) model is shown below:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\nr2_score(y,y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Root mean square error for the Model built, is show below:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nnp.sqrt(mean_squared_error(y,y_train_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##So, above we saw that the predicted values given by the stats model and the machine learning regression were different\n##And that was because the accuracy achieved in both the cases were different\n##Ideally, we desire a model that has high accuracy (Rsquare) without overfit, and a lower RMSE\n##So, we see that on building the machine learning model, the RMSE does decrease by a little amount, but the Rsquare\n#decreases by a large amount\n##so, in this particular case, we will select our Statistics Model as the preferred one","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Part 4. Top Hex clusters\nTop 5 pairs of hex (resolution=8) clusters where most of the trips happened? You can refer to the library listed below to get hexid for a given latitude and longitude.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport folium\nimport webbrowser\nimport os\nimport math\n\nfrom h3 import h3\nfrom folium import Map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos = df[['pick_lat','pick_lng','drop_lat','drop_lng']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Creating radian latitude and logitude columns now","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos['lngpick'] = np.radians(pos['pick_lng'].to_numpy())\npos['latpick'] = np.radians(pos['pick_lat'].to_numpy())\npos['lngdrop'] = np.radians(pos['drop_lng'].to_numpy())\npos['latdrop'] = np.radians(pos['drop_lat'].to_numpy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos1 = pos[['lngpick','latpick']]\npos2 = pos[['lngdrop','latdrop']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Setting parameters for DBSCAN:\neps_in_meters = 50.0\nnum_samples = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##First finding out where most of the trips started:\nfrom sklearn.cluster import DBSCAN\n\nearth_perimeter = 40070000.0  # In meters\neps_in_radians = eps_in_meters / earth_perimeter * (2 * math.pi)\n\npos1['cluster'] = DBSCAN(eps=eps_in_radians, min_samples=num_samples, \n                           metric='haversine').fit_predict(pos1[['lngpick', 'latpick']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h3_level = 8 ##as defined in the question","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Function to convert latitude and longitudes to H3 key:\ndef lat_lng_to_h3(row):\n    return h3.geo_to_h3(row['lngpick'], row['latpick'], h3_level)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos1['h3'] = pos1.drop(columns='cluster').apply(lat_lng_to_h3, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Selecting only the locations that belong to a DBSCAN-generated cluster. Clusters marked with -1 are noise in this case:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pos1[pos1.cluster != -1].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['h3'].value_counts()  ##H3 levels for the positions where the pick location was","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1['cluster'].value_counts().head(5) ##Top 5 clusters for the positions where the pick location was","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Now, for the Drop location where most trips ended:\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos1 = pos[['lngpick','latpick']]\npos2 = pos[['lngdrop','latdrop']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Setting parameters for DBSCAN:\neps_in_meters = 50.0\nnum_samples = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##First finding out where most of the trips started:\nfrom sklearn.cluster import DBSCAN\n\nearth_perimeter = 40070000.0  # In meters\neps_in_radians = eps_in_meters / earth_perimeter * (2 * math.pi)\n\npos2['cluster'] = DBSCAN(eps=eps_in_radians, min_samples=num_samples, \n                           metric='haversine').fit_predict(pos2[['lngdrop', 'latdrop']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h3_level = 8 ##as defined in the question","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Function to convert latitude and longitudes to H3 key:\ndef lat_lng_to_h3(row):\n    return h3.geo_to_h3(row['lngdrop'], row['latdrop'], h3_level)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos2['h3'] = pos2.drop(columns='cluster').apply(lat_lng_to_h3, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Selecting only the locations that belong to a DBSCAN-generated cluster. Clusters marked with -1 are noise in this case:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = pos2[pos2.cluster != -1].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2['h3'].value_counts()  ##H3 levels for the positions where the pick location was","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2['cluster'].value_counts().head(5) ##Top 5 clusters for the positions where the pick location was","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##So, we have calculated top 5 clusters based on pick locations and drop locations\n##We do see that people are usually travelling from one specific location to another, and this is actually true, since\n#quite a lot of people will be taking trips from highly occupied residential areas, to their workplace/institutes, etc.\n##We can take an example of people travelling from HSR layout/Koramangala to various co-working spaces in Bangalore, \n#so the amount of #picks from residential areas could be highest, and the amount of drops at the co-working spaces could be\n#highest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}